---
layout: post
title: "Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization"
date:   2020-8-21
excerpt: ""
tags: []
feature: ../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Gradcam.png 
comments: true
---


    
<style>
a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}


    h1 {
        font-size: 1.875rem;
        margin-top: 5.5rem; 
    }

    h2 {
        font-size: 1.5rem;
        margin-top:4rem;
    }

    h3 {
        font-size: 1.25rem;
        margin-top: 3.5rem;
    }
    .source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, YuMincho, "Yu Mincho", "Hiragino Mincho ProN", "Hiragino Mincho Pro", "Songti TC", "Songti SC", "SimSun", "Nanum Myeongjo", NanumMyeongjo, Batang, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC', 'Noto Sans CJK KR'; }

.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC', 'Noto Sans Mono CJK KR'; }

.highlight-default {
}
.highlight-gray {
	color: rgb(155,154,151);
}
.highlight-brown {
	color: rgb(100,71,58);
}
.highlight-orange {
	color: rgb(217,115,13);
}
.highlight-yellow {
	color: rgb(223,171,1);
}
.highlight-teal {
	color: rgb(15,123,108);
}
.highlight-blue {
	color: rgb(11,110,153);
}
.highlight-purple {
	color: rgb(105,64,165);
}
.highlight-pink {
	color: rgb(173,26,114);
}
.highlight-red {
	color: rgb(224,62,62);
}
.highlight-gray_background {
	background: rgb(235,236,237);
}
.highlight-brown_background {
	background: rgb(233,229,227);
}
.highlight-orange_background {
	background: rgb(250,235,221);
}
.highlight-yellow_background {
	background: rgb(251,243,219);
}
.highlight-teal_background {
	background: rgb(221,237,234);
}
.highlight-blue_background {
	background: rgb(221,235,241);
}
.highlight-purple_background {
	background: rgb(234,228,242);
}
.highlight-pink_background {
	background: rgb(244,223,235);
}
.highlight-red_background {
	background: rgb(251,228,228);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(55, 53, 47, 0.6);
	fill: rgba(55, 53, 47, 0.6);
}
.block-color-brown {
	color: rgb(100,71,58);
	fill: rgb(100,71,58);
}
.block-color-orange {
	color: rgb(217,115,13);
	fill: rgb(217,115,13);
}
.block-color-yellow {
	color: rgb(223,171,1);
	fill: rgb(223,171,1);
}
.block-color-teal {
	color: rgb(15,123,108);
	fill: rgb(15,123,108);
}
.block-color-blue {
	color: rgb(11,110,153);
	fill: rgb(11,110,153);
}
.block-color-purple {
	color: rgb(105,64,165);
	fill: rgb(105,64,165);
}
.block-color-pink {
	color: rgb(173,26,114);
	fill: rgb(173,26,114);
}
.block-color-red {
	color: rgb(224,62,62);
	fill: rgb(224,62,62);
}
.block-color-gray_background {
	background: rgb(235,236,237);
}
.block-color-brown_background {
	background: rgb(233,229,227);
}
.block-color-orange_background {
	background: rgb(250,235,221);
}
.block-color-yellow_background {
	background: rgb(251,243,219);
}
.block-color-teal_background {
	background: rgb(221,237,234);
}
.block-color-blue_background {
	background: rgb(221,235,241);
}
.block-color-purple_background {
	background: rgb(234,228,242);
}
.block-color-pink_background {
	background: rgb(244,223,235);
}
.block-color-red_background {
	background: rgb(251,228,228);
}
.select-value-color-default { background-color: rgba(206,205,202,0.5); }
.select-value-color-gray { background-color: rgba(155,154,151, 0.4); }
.select-value-color-brown { background-color: rgba(140,46,0,0.2); }
.select-value-color-orange { background-color: rgba(245,93,0,0.2); }
.select-value-color-yellow { background-color: rgba(233,168,0,0.2); }
.select-value-color-green { background-color: rgba(0,135,107,0.2); }
.select-value-color-blue { background-color: rgba(0,120,223,0.2); }
.select-value-color-purple { background-color: rgba(103,36,222,0.2); }
.select-value-color-pink { background-color: rgba(221,0,129,0.2); }
.select-value-color-red { background-color: rgba(255,0,26,0.2); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style>
<div class="page-body"><p id="5c79cb07-0d96-4255-8cf4-34cfa72d21d2" class="">CAM 논문을 읽었다면 Grad-CAM을 읽게 되는 건 어떻게 보면 당연할지도....</p><p id="f1d99ca4-dbf5-4380-8b62-ff95df68d87e" class="">
</p><h1 id="be51c62b-0fb0-441d-bd1e-41ca14e6ca0d" class="">Introduction</h1><p id="adc300ac-f579-4d7c-beb5-cb7afef0a59b" class="">이번 논문에서 제안하는 모델은 Gradient-weighted Class Activation Mapping (Grad-CAM)이다.</p><p id="737653d1-692a-40d8-b76d-c02bfd406f21" class="">CAM 논문을 읽었다면 벌써 어떤 목적으로 이 모델을 제안했는지 알게 될 것이다.</p><p id="861226bf-e111-4fd7-918b-5a7ad5ba235a" class="">
</p><p id="73b71d61-e122-4ffb-bc52-df38d8c5e83e" class=""><strong>CAM 논문을 읽지 않았다면 아래 링크에서 먼저 보고 오자!</strong></p><figure id="3a1064f3-eb7d-42d3-a569-42f34a26ebd0" class="link-to-page"><a href="https://www.notion.so/Copy-of-Learning-Deep-Features-for-Discriminative-Localization-3a1064f3eb7d42d3a56942f34a26ebd0"><span class="icon">👨‍💼</span>Copy of Learning Deep Features for Discriminative Localization</a></figure><p id="3e5e9c1a-dfa3-4601-a274-d622bbca7447" class="">
</p><p id="8fb75955-3d6c-4414-b4cd-48f90b8e3de7" class="">Computer vision에서 CNN의 성공은 Deep learning의 폭발적인 관심을 불러일으켰지만 여전히 설명력의 부족이라는 한계를 가지고 있다.</p><p id="7b41c3f7-d750-4b22-baa8-78a333f8c23f" class="">
</p><p id="37d6af81-fa27-4bb7-8721-8992d13de62e" class="">저자들은 모델이 설명력을 가져야 하는 이유를 사람과의 상호작용에서 찾고 있다.</p><ol id="2c72715f-e372-4e13-9e03-29d187de902e" class="numbered-list" start="1"><li>when AI is significantly weaker than humans and not yet reliably ‘deployable’<p id="ff0ffcc2-504a-4236-974c-e6874d796df3" class="">→ 모델이 왜 성능이 낮은지 알기 위해</p></li></ol><ol id="47407e24-c8fc-4112-9ec2-e0cf82f4d1e9" class="numbered-list" start="2"><li>when AI is on par with humans and reliably ‘deployable’<p id="b02257f9-feae-4644-b528-b5e4d89035df" class="">→ 모델의 신뢰도를 얻기 위해</p></li></ol><ol id="5c963f62-d251-4ae1-afb3-2c724fe89635" class="numbered-list" start="3"><li>when AI is significantly stronger than humans<p id="38abcfc0-518c-4e51-9eb1-c318d1d363c2" class="">→ 인간이 AI에게 배우기 위해</p></li></ol><p id="7196d7ed-e23b-4bff-8717-71b4d6c4494b" class="">
</p><p id="fea87ed3-7ee8-44cf-8df6-7537b5dc94fd" class="">사실 설명력이 중요한 이유는 너무나 명확하기 때문에 모두가 그 중요성을 인지하고 있다.</p><p id="8ad951ae-2693-422c-8fb5-58dd5fe51661" class="">하지만, 왜 Deep learning 모델은 설명력을 갖지 못할까? </p><p id="caebb030-74ed-4d8b-ab91-a9391464e3c1" class="">
</p><p id="cd6f27d3-111d-4394-8ca3-6271c80512f7" class=""><strong>일반적으로 모델의 복잡성(≈ 성능)과 모델의 설명력은 trade-off 관계에 있기 때문이다.</strong></p><p id="f0b34749-3492-4bf8-adfc-1c70b1baacb8" class="">GPU의 발전은 Network의 깊이를 더욱 깊게 만들었고 모델의 성능을 얻은 대신 설명력을 잃어버렸다. </p><p id="a70901dc-3954-4281-b565-10975e3643f1" class="">
</p><p id="32aca64f-47ef-4bbb-88c4-9cc8158952b0" class="">이번 논문의 이야기로 돌아와서 CAM의 경우를 보자.</p><p id="67269cf4-6373-4ff3-bfa6-211aca7aaee7" class="">CAM의 경우, 모델의 마지막 Fully connected layer를 Global average pooling으로 바꿔 모델을 단순화시켰다.</p><p id="11c96460-cd7f-48df-a37e-6e0daa78759f" class="">이런 변형으로 설명력을 얻었지만 기존 모델의 성능에 비해 다소 떨어진 성능을 보였다.</p><p id="e1c7c229-c070-4ca5-a7bf-c2b98a3b05df" class="">
</p><p id="6fca2e12-d193-4b74-b540-284361d0ceb5" class="">모델의 구조를 바꾸는 것은 필연적으로 모델의 성능 저하를 일으킨다.</p><p id="7d66e70b-e7a5-40c5-9645-46b8f6e31e87" class="">따라서 저자들은 모델의 구조를 전혀 바꾸지 않으면서 설명력을 가지게 하는 방법을 제안한다.</p><p id="28cd0291-b9de-4074-b31e-644a77ab5859" class="">
</p><p id="4f1fe7a1-cdce-45af-ac38-bda6403f4902" class="">
</p><h1 id="5120d1c4-664a-4f49-b61b-0ff95b3dcdba" class="">What makes a good visual explanations?</h1><p id="699ccefb-5b00-4075-bf1d-cc6ba53f1da2" class="">Computer vision에서 모델의 설명력이 가져야할 좋은 특성은 다음과 같다. </p><p id="af34dc0e-22f1-4d16-aebb-d3c4692acf00" class="">
</p><ol id="329a4325-5f91-42cf-abef-c1d45b7079e5" class="numbered-list" start="1"><li><strong>Class discriminative : </strong>모델의 설명력은 Class에 따라 구별되는 특성을 보여야 한다.<p id="51b435cc-5dda-44c4-a968-02abeb50516e" class="">아래의 그림은 Class discriminative 특성을 갖고 있지 않다.</p><figure id="20abcf04-61b9-4149-be9f-44efaa3aeb8c" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled.png"><img style="width:480px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled.png"/></a></figure><p id="499eece5-42fb-453e-90ab-64ae1efde6cb" class="">
</p><p id="4b44d8e8-21f8-4c05-b67f-624f3f10cf97" class="">좋은 Class discriminative 특성을 가진 모델은 다음과 같이 구별적인 설명이 가능해야 한다.</p><figure id="fbee17e7-4abc-4497-8eb6-02b56cee3605" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%201.png"><img style="width:480px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%201.png"/></a><figcaption>순서대로 Cat, Dog</figcaption></figure><p id="ba06efa0-98c1-4fb4-9107-3c1f4c7c2975" class="">
</p></li></ol><ol id="f7ff6737-6939-42d2-873f-9bd44ea36041" class="numbered-list" start="2"><li><strong>High-resolution : </strong>모델의 설명력은 fine-grained detail도 포함해야 한다.<p id="5ca17ccf-65fe-4508-a320-4cb5e6a61b8a" class="">모델이 아무리 설명을 잘할지라도 resolution이 너무 낮다면 인간이 사용하기에 유의미한 결과를 도출하기가 어렵다.</p><figure id="1f9db4d3-c68f-4650-bfda-8bb856b5416d" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%202.png"><img style="width:480px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%202.png"/></a></figure><p id="6be33244-3e9e-43af-9567-64feedea26fe" class="">
</p></li></ol><h1 id="f6edfeb8-02d1-493f-931a-66d20536a41e" class="">Gradient-weighted Class Activation Mapping (Grad-CAM)</h1><p id="18d7b791-34bc-4dc6-b448-82aa4c90b786" class="">
</p><p id="a73c8a90-7370-40c7-9f48-9a39ad42cca9" class="">Grad-CAM은 CAM의 일반화 모형이라고 저자들은 설명한다.</p><p id="027c8be4-6a5a-47c6-a2d9-41a4dafbb263" class="">Grad-CAM은 마지막 Convolution layer의 feature map에 class에 따른 gradient를 곱해 이미지 분류를 위해 중요한 부분에 대한 localization map을 구한다.</p><p id="74302e1a-b599-4a73-8ee1-9161e4e5a747" class="">
</p><h3 id="317102ef-5162-43f9-945b-6ff23091c2b6" class="">구현 방법</h3><p id="546aa54e-94c1-421a-9069-8a007c7ee1b2" class=""><strong>notation</strong></p><p id="829240b4-e845-4735-8f43-88575a5ab59b" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mi>k</mi></msup><mo>∈</mo><msup><mi mathvariant="double-struck">R</mi><mrow><mi>u</mi><mo>×</mo><mi>v</mi></mrow></msup></mrow><annotation encoding="application/x-tex">A^{k} \in \mathbb{R}^{u \times v}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888208em;vertical-align:-0.0391em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.771331em;vertical-align:0em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">R</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.771331em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span><span class="mbin mtight">×</span><span class="mord mathdefault mtight" style="margin-right:0.03588em;">v</span></span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>  : 마지막 convolution layer의 k번째 feature map (<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">u</span></span></span></span></span><span>﻿</span></span> : width, <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">v</span></span></span></span></span><span>﻿</span></span> : height)</p><p id="c029f458-834d-4065-b45d-cdd88b656413" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mi>c</mi></msup></mrow><annotation encoding="application/x-tex">y^{c}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.858832em;vertical-align:-0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>  : Label c 예측에 대한 score <div class="indented"><figure class="block-color-yellow callout" style="white-space:pre-wrap;display:flex" id="7b4bf3bd-9e2d-4ec0-8d1a-c0d6d477e323"><div style="font-size:1.5em"><span class="icon">💡</span></div><div style="width:100%">논문에서 구체적인 설명은 없는데 이후에 ReLU를 통해서 양수부분만 남기는 것을 보면 loss보다는 score로 보는 것이 맞을듯하다.
class에 따른 score를 구해야하기 때문에 softmax 전후에 있는 값을 사용할 것으로 추정된다. </div></figure></div></p><p id="2e687a04-c178-47d5-ae97-9a6298889f13" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>k</mi></msubsup></mrow><annotation encoding="application/x-tex">A^{k}_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2438799999999999em;vertical-align:-0.394772em;"></span><span class="mord"><span class="mord mathdefault">A</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.849108em;"><span style="top:-2.441336em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right:0.05724em;">j</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.394772em;"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span> : k번째 feature map의 (<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathdefault">i</span></span></span></span></span><span>﻿</span></span>,  <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.05724em;">j</span></span></span></span></span><span>﻿</span></span>) 좌표의 값  </p><p id="18e72152-f194-4799-b44a-c7307b75fc25" class="">
</p><p id="ee616295-44db-4bd2-aee1-7151067bf427" class="">Grad-CAM을 계산하는 방법은 크게 두 가지 과정으로 나뉜다.</p><ol id="fe78e303-f7b8-4b40-b7a4-3161c8f3ecdd" class="numbered-list" start="1"><li>Feature map weight 구하기.<figure id="3889658b-b8cd-47cc-9b3e-4231daab96ff" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><div>$$\alpha_{k}^{c}=\frac{1}{Z} \sum_{i} \sum_{j}\frac{\partial y^{c}}{\partial A_{i j}^{k}}$$</div></figure><p id="9a70c9a0-4b6a-44ee-b222-5f88eaf174b9" class="">feature map의 gradient 값을 모두 더해 feature map의 weight을 구한다.</p><p id="d36be524-0598-4576-9c45-8b42d5e63b6d" class="">
</p></li></ol><ol id="1677a255-2cdd-4886-acc8-a7f8a1b26f4d" class="numbered-list" start="2"><li>feature map의 각 점에서 중요도 찾기 (최종 localization map)<figure id="0020bac9-769b-4db5-97c6-759a633eaa50" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css')</style><div>$$L_{\mathrm{Grad}-\mathrm{CAM}}^{c}=\operatorname{ReLU}\left(\sum_{k} \alpha_{k}^{c} A^{k}\right)$$</div></figure><p id="bcdb0d5b-cf1b-4e03-99db-bef8c01ee57b" class="">feature map의 동일 위치 점에 대해서 각 feature map의 weight을 곱한 후 더한다.</p><p id="b5c298ae-34b7-417b-a05c-b1479268754c" class="">더해진 값을 ReLU 함수에 넣는다.</p><p id="a8dd81fe-7047-4346-9ee9-da30e3e183e0" class="">
</p><p id="141e020b-25d4-4a7d-8ac1-dde6f15a07cd" class=""><strong>Why ReLU?</strong></p><p id="bb379d97-e9cc-48e4-bb0b-3fcd0e42370a" class="">ReLU의 효과는  score를 증가시키기 위해  더해야 하는 항목의 gradient만 남기는 것이다.</p><p id="12c1ce5b-1211-4aed-9e82-9ea0ec118f2e" class="">ReLU를 하지 않을 경우, 음의 값을 갖는 값들 역시 localization map을 구할 때 강조가 되기 때문에 더 명확한 해석력을 위해 음수값들을 전부 0으로 바꿔준다.</p></li></ol><p id="1b814f2c-4986-465b-baf1-d572f4dcd7af" class="">
</p><h3 id="af54f927-fece-4d5b-9f82-e386fd55c6e6" class="">Grad-CAM의 결과 예시</h3><p id="c27f3a09-11a4-45c5-88e9-d184df4303d9" class="">label &#x27;Cat&#x27;에 대해서 Grad-CAM을 실행하면 다음과 같은 결과를 얻을 수 있다.</p><figure id="988a5506-2411-4258-86af-fbfd8366e6e0" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%203.png"><img style="width:480px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%203.png"/></a><figcaption>&#x27;Cat&#x27;에 대한 Grad-CAM 예시</figcaption></figure><p id="357f2389-edc5-413d-9b7d-e7cbbb9d7736" class="">
</p><p id="cb9952f1-3e9a-4283-b89e-feab55a97ee7" class="">고양이가 있는 위치를 Grad-CAM을 통해서 명확히 찾을 수는 있었지만 한 가지 부족한 점이 있다. </p><p id="f54fd8d1-6784-4813-89cc-0c5e39a80d4b" class="">좋은 해석력이 가져야 하는 조건에 우리는 High-resolution에 대해서 언급한 적이 있다.</p><p id="00ee820a-a7c9-406f-939b-73fa1e1897a4" class="">하지만, Grad-CAM은 High resolution 조건을 만족하지 못한다.</p><p id="a7d5e1cd-d119-4be8-90e6-54c1a058a57a" class="">
</p><p id="ee409a2c-30b0-4936-a27d-829336395fca" class="">이것은 Grad-CAM이 최종 Convolution layer의 feature map에 대해서 실행되기 때문이다. </p><p id="354608c3-91d6-4286-a058-3a85e4b4cce2" class="">Grad-CAM의 output은 필연적으로 feature map의 크기와 같다.</p><p id="257e3558-b0e5-49d9-a4aa-08dab59b747b" class="">일반적으로 Convolution layer 통해서 input의 크기가 점점 줄어드는 것을 생각해보면 Grad-CAM의 low-resolution이 이해가 될 것이다.</p><p id="01cb8d89-9c72-4e7e-95b9-944ecea51c63" class="">
</p><p id="60a28e85-027a-4cac-86cc-f565c85d6295" class="">이런 단점을 극복하기 위해서 나온 구체적인 방법이 Guided Grad-CAM이다.</p><p id="85c0d004-5e80-4acc-8e18-76117230a6ad" class="">
</p><h1 id="1a8f197a-913d-49c7-a234-13e151be4243" class="">Guided Grad-CAM</h1><p id="65de4738-0611-44e8-b06b-d5cfdce44efc" class="">Grad-CAM의 low resolution 문제를 해결하기 위해 Guided Backpropagation을 도입한다.</p><p id="7c50a07a-2538-4607-8b7d-d6a46a619961" class="">
</p><h3 id="4404c860-c08a-443f-bef5-07047fbd1d10" class="">Guided backpropagation</h3><p id="84a3666e-7e92-4f8f-8b27-4564ef302fdc" class="">우선 Guider backpropagation에 대해서 먼저 보자.</p><p id="723778e4-49fc-4541-8939-b1f4b9d3d04a" class="">Forward pass의 activation function를 ReLU라고 하자.</p><figure id="a797d949-bf79-4366-86b3-f01e19b9513c" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%204.png"><img style="width:411px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%204.png"/></a></figure><p id="dafd8530-7400-45aa-8df2-38a1f0d4e55f" class="">backpropagation은 forward pass의 ReLU output이 양수인 부분에 대해서만 학습이 진행된다.</p><figure id="ff03f0cf-9265-4107-9f69-82dc678f1b8e" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%205.png"><img style="width:395px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%205.png"/></a></figure><p id="8d6a6928-7c5b-4cb1-8321-72d7d26cf7ef" class="">deconvnet에서는 gradient가 양수인 부분에 대해서만 학습이 진행된다.</p><figure id="e22f4279-e5d9-4670-af10-5c2c3ed39df8" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%206.png"><img style="width:403px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%206.png"/></a></figure><p id="f1a3eb39-b50b-4a71-85c5-95921dbcdd8b" class="">마지막으로 Guided backpropagation은 ReLU output과 gradient가 모두 양수인 부분에 대해서만 학습이 진행된다.</p><figure id="133dc38b-7766-4837-a55d-522b1e08d24a" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%207.png"><img style="width:400px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%207.png"/></a></figure><p id="fc2a4f2a-df7b-4fb3-a5a0-61021df72a4e" class="">
</p><h3 id="0ae78e9a-7ce3-4307-8e73-536cc1836cf9" class="">Guided Grad-CAM을 얻는 방법</h3><p id="2873154e-8c79-4872-9f66-64391ba99a9b" class="">Grad-CAM과 Guided backpropagation을 이용해서 Guided Grad-CAM을 얻는 구체적인  방법을 알아보자.</p><figure id="2c1802d1-429e-4803-86b9-0b750dabedf1" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%208.png"><img style="width:624px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%208.png"/></a><figcaption>Guided Grad-CAM을 얻는 방법</figcaption></figure><ol id="22b1d8c5-f67b-415c-addc-8e00e87da011" class="numbered-list" start="1"><li>Guided Backpropagation을 구한다.</li></ol><ol id="527347d4-70fc-4d69-9feb-c75614ebdcf3" class="numbered-list" start="2"><li>bi-linear interpolation을 이용해 Grad-CAM을 Up-sampling한다.</li></ol><ol id="194b588b-d5e8-4f3f-9e91-c1fdb4b76cd6" class="numbered-list" start="3"><li>Guided Backpropagation과 Up-sampled Grad-CAM을 pointwise multiplication을 통해서 Guided Grad-CAM을 구한다.</li></ol><p id="d8291082-36ff-48be-80ae-9dbd89b8fe66" class="">
</p><p id="a083b048-8b73-49f5-aaa3-2280a301712d" class="">
</p><h1 id="e449add1-67bc-4539-bc4e-8a3f13924742" class="">Experiments</h1><p id="6e5b6c5f-2af8-4c01-a995-edf4926f9ccb" class="">Intro에서 AI와 인간의 상호작용을 위해 설명력이 필요함을 강조했다.</p><p id="149a0645-1156-42cb-bbef-7b8725da6cec" class="">그래서 다음 실험 결과에 매우 흥미를 느낄 수 있었다.</p><p id="22e63f4b-c43e-4685-9a77-12f6e1685fe8" class="">
</p><p id="25792368-a09a-4cf3-8dd8-052a63f9d052" class="">설명력이 뛰어난 모델은 모델의 예측이 틀린 이유를 사람이 납득할 수 있게 설명해야 한다.</p><p id="7f9e7c85-4c77-40de-aa47-2e62086bfa26" class="">아래는 논문에 실린 오답에 대한 예시와 왜 모델이 이런 예측을 했는지 유추할  수 있는 Guided Grad-CAM 결과를 포함하고 있다.</p><figure id="da30a058-ff59-4562-b914-5d4d9ae88752" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%209.png"><img style="width:474px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%209.png"/></a></figure><p id="abce2a61-a54b-4be6-a141-404554f72bee" class="">
</p><figure id="4bca3f28-c469-40aa-90d9-ef2a088aea09" class="image"><a href="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%2010.png"><img style="width:449px" src="../assets/img/Grad-CAM%20Why%20did%20you%20say%20that%20Visual%20Explanations%20%2020abcf0461b94149be9f44efaa3aeb8c/Untitled%2010.png"/></a></figure><p id="99b9fe4d-6ea3-4a34-bac0-0b531deaf5e9" class="">
</p><p id="b6fccac3-017a-4270-83d1-c2aa19cfdd20" class="">결과들은 매우 흥미롭다. 모델이 Ground truth와는 다른 예측을 했지만 인간이 보기에도 이렇게 예측하는 것이 그렇게 틀리지는 않았다는 생각이 드는 사례가 많다.</p><p id="702a3246-44e6-47a2-bfb7-679dcc17f51e" class="">(이렇게 Labeling 중요성을 또 한 번 배우고 간다...)</p><p id="2c97abef-5842-4301-a3ad-9599c6b9a4af" class="">
</p><h1 id="0f4da838-6f3d-45ff-9f15-d7fe5c2d89f8" class="">Reference</h1><p id="9c104dbd-b406-4f73-a3ce-beee0dca7570" class="">[1] Springenberg, Jost Tobias, et al. &quot;Striving for simplicity: The all convolutional net.&quot; arXiv preprint arXiv:1412.6806 (2014).</p></div>